\capitulo{3}{Conceptos teóricos}

Para comprender el marco teórico del desarrollo de este proyecto, es fundamental contar con un conocimiento previo de los conceptos en los que se basa.

\section{Fórmula 1} 

La \href{https://www.formula1.com/}{Fórmula 1} es una competición automovilística que dio inicio en 1950. En la actualidad es considerada la más prestigiosa del mundo y también es la serie deportiva anual con mayor popularidad. Este campeonato está regulado por la la FIA (Federación Internacional del Automóvil) y actualmente está compuesta por 10 equipos con dos coches cada uno. Dicho certamen se lleva a cabo desde marzo hasta noviembre, con un total de 23 carreras disputadas en 20 países distribuidos en cuatro continentes \cite{f1:f1}.

\section{IA - Inteligencia Artificial}

La Inteligencia Artificial o IA se podría definir como la capacidad de las máquinas para tomar decisiones tal como lo hace el ser humano. Para ello se vale de diferentes algoritmos y en el aprendizaje sobre una gran cantidad de datos. Algunos sostienen que la inteligencia radica en las propiedades de los procesos internos de pensamiento y razonamiento, mientras que otros la definen en términos de comportamiento inteligente, una caracterización externa \cite{aimodaproach}.

\section{Modelo predictivo}

Un modelo predictivo es un modelo de datos, basado en estadísticas inferenciales, que se utiliza para predecir resultados. Consiste en un conjunto de herramientas y técnicas estadísticas que sirven para pronosticar y predecir el comportamiento ante un evento. 

Aplicado al campo de la inteligencia artificial, podríamos decir que un modelo de predicción no es más que un modelo de caja negra para hacer predicciones \cite{art:predictmodel}, lo que significa que no se requiere un conocimiento detallado de su funcionamiento interno para utilizarlo. Los modelos predictivos utilizan técnicas basadas en el aprendizaje automático para hacer predicciones basadas en datos históricos o patrones identificados en los datos de entrenamiento. Dichos modelos aprenden automáticamente de los datos de entrenamiento y generan predicciones basadas en su capacidad para identificar patrones ocultos en los datos de entrada.

\section{Aprendizaje automático}

El aprendizaje automático o machine learning es un subcampo de la inteligencia artificial que, a su vez es una técnica que mejora el rendimiento de un sistema mediante el uso de la computación a través de la experiencia. Los datos son la forma principal de experiencia en los sistemas informáticos, y el objetivo principal del aprendizaje automático es crear algoritmos de aprendizaje que creen modelos a partir de datos. Al proporcionar al algoritmo de aprendizaje datos de experiencia, podemos crear un modelo que puede pronosticar los resultados de futuras observaciones. Si consideramos la informática como el tema de los algoritmos, entonces el aprendizaje automático es el tema de los algoritmos de aprendizaje \cite{machinelearning}.

En este proyecto vamos a emplear algoritmos de aprendizaje automático diferenciados en dos grupos: algoritmos de regresión y de clasificación.

Algoritmos de regresión:

\begin{itemize} \label{algoritmosreg}
    \item Linear Regression: este modelo tiene como objetivo crear una relación lineal entre la variable objetivo y las demás variables. Se aplica a problemas de regresión donde el objetivo es predecir valores numéricos. Además este modelo es sumamente eficiente en cuanto a computación.
    \item Decision Tree Regressor: es un modelo que se basa en árboles de decisión. Crea una estructura de árbol tratando de que las ramas representen posibles respuestas a las preguntas que forman los nodos con respecto a las características. Cada hoja del árbol recibe un valor de salida tras la división recursiva en subconjuntos del conjunto inicial de datos. Se aplica en problemas que requieran identificar relaciones no lineales.
    \item Random Forest Regressor: el propósito del modelo es hacer predicciones a través de la combinación de varios árboles de decisión. El resultado final se obtienen promediando las predicciones de cada uno de los arboles, los cuales se han entrenado con una muestra aleatoria diferente a las demás. Además, cuenta con la ventaja de reducir el sobreajuste y aumentar la eficiencia. Es aplicado a problemas con características de alta dimensión y puede gestionar un gran volumen de datos.
    \item Support Vector Regression: modelo que predice utilizando vectores de soporte. Los puntos de los vectores de soporte se encuentran en el borde del límite de decisión o en la zona que afectará en mayor medida cómo se define la función de regresión. El modelo controla una tolerancia de error, buscando una función de regresión que se ajuste mejor a los datos y reduzca la discrepancia entre la predicción y el valor real. Cuando nuestros datos contienen características no lineales o incluso con valores atípicos, este modelo es sumamente útil en problemas de regresión.
\end{itemize}

Algoritmos de clasificación:

\begin{itemize} \label{algoritmosclas}
    \item Logistic Regression: es utilizado para resolver problemas donde las variables objetivo son binarias o representan categorías. Se usa una función logística para calcular la probabilidad con la que una instancia dada pertenezca a una clase en particular. Se sustenta en la relación lineal encontrada entre características y variable objetivo. Además, convierte el resultado en una probabilidad gracias a una función de activación. Utilizado sobre todo para problemas de clasificación binaria, pero se puede expandir a problemas con variables objetivo categóricas.
    \item Decision Tree Classifier: funciona igual que el Decision Tree Regressor pero con la particularidad de que en este cada hoja del árbol recibe una etiqueta de clase tras la división recursiva del conjunto de datos y no un valor.
    \item Random Forest Classifier: al igual que en la regresión, realiza las predicciones a través de la combinación de varios árboles de decisión. El resultado se obtiene promediando la clasificación total de los árboles.
    \item Support Vector Classification: los vectores utilizados en este modelo se usan para dividir instancias en clases. La diferencia con el SVR es que ahora buscamos el mejor hiper plano en el cual haya la mayor distancia de mayor entre clases. Permite el uso de datos tanto linealmente separables como no separables gracias a funciones kernel. Gran elección en problemas de clasificación de variables categóricas o binarias.
    \item KNeighbors Classifier: usa el algoritmo K-Nearest Neighbors. Asigna etiquetas de los k vecinos cercanos a las instancias. Se vale de la noción de que las instancias parecidas pertenecen a la misma clase con frecuencia. Es muy eficiente y sencillo para problemas de clasificación siempre y cuando la elección del número de k vecinos no sea demasiado alta.
    \item Gaussian NB (Naive Bayes): este modelo se basa en el teorema de Bayes, además de asumir que los datos forman una distribución gaussiana. Utiliza la regla de Bayes para determinar la probabilidad de pertenecer a una clase en particular. Se asume la independencia entre características, algo ingenuo, de ahí su nombre. Para problemas de clasificación con variables continuas y distribuidas en forma normal es muy eficiente.
\end{itemize}

Además, estos algoritmos pueden usarse en combinación con diferentes estrategias para realizar una selección de características, como se ha utilizado para este desarrollo. Entre ellas encontramos la estrategia de eliminación hacia atrás que comienza con todas las características y elimina una a una en cada iteración. Esto es, en cada iteración de esta técnica se entrena y evalúa un modelo con las variables disponibles. La característica menos significativa es la eliminada, tomando como criterio el peso de la misma en esa iteración. Esto se repite hasta llegar al criterio de parada.
\label{RFE}
Pero para ello debemos usar técnicas como el algoritmo RFE o \textit{Recursive Feature Elimination}, que es un tipo de eliminación hacia atrás, pero tiene la ventaja de ser compatible con varios algoritmos de aprendizaje automático, lo que lo convierte en una herramienta flexible y adaptable. Se puede combinar con algoritmos de regresión, clasificación u otras estrategias de modelado, brindándonos la flexibilidad de manejar varios problemas y conjuntos de datos. Además, proporciona una medida de importancia o relevancia para cada característica en función de cómo contribuye al modelo final. Dado que nos permite identificar los rasgos que tienen mayor influencia en la toma de decisiones del modelo, será particularmente útil para nuestro propósito.


\section{Python}

Python \cite{python} es un lenguaje de programación orientado a objetos, interpretado e interactivo que posee características como la inclusión de módulos, excepciones, tipado dinámico, tipos de datos de alto nivel y clases. Debido a su gran cantidad de librerías y programadores, es muy popular y ampliamente utilizado en diferentes campos de la programación, lo que permite realizar diversos propósitos. Además, se le considera un lenguaje de alto nivel que ofrece una sintaxis clara y sencilla de comprender. 

Fue creado a principios de la década de 1990 por Guido van Rossum en Stichting Mathematisch Centrum (CWI) en los Países Bajos como sucesor de un idioma llamado ABC \cite{pythonhistory}. 

Además, este lenguaje de programación es muy popular y ampliamente utilizado en el campo de la inteligencia artificial, ofreciendo una serie de librerías especializadas como pueden ser TensorFlow, Keras, PyTorch, y Scikit-learn, que facilitan la implementación de algoritmos de aprendizaje automático y procesamiento de datos. 

\imagen{most_used_languages}{lenguajes de programación mas usados desde 2010 a 2022 \cite{pythonuse}. Basado en el porcentaje de preguntas en \textit{Stack Overflow}, uno de los portales de preguntas y respuestas sobre programación más importantes de todo el mundo.}{}


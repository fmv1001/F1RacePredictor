\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

Esta sección tiene como objetivo recopilar las facetas más fascinantes de la evolución del proyecto, desde la exposición del ciclo de vida empleado hasta los detalles más cruciales de las fases de análisis, diseño e implementación.

\section{Elección del tema}

Desde mi infancia he tenido la suerte de poder interactuar con el apasionante mundo del deporte y más en concreto de la Fórmula 1. Puedo recordar claramente haber visto carreras en la televisión con mi familia y maravillarme con la velocidad, la habilidad y la emoción que caracterizan a este deporte de élite. También, esa época coincidió con el éxito de nuestro representante en este deporte, Fernando Alonso. Viví sus dos mejores años, 2005 y 2006. Jamás olvidaré sus luchas con Michael Schumacher, considerado uno de los mejores pilotos de la historia sino el mejor.

Con el tiempo mi terés por la Fórmula 1 se hizo más fuerte. Comencé por investigar a los pilotos más laureados y a los equipos míticos que han dejado una larga huella en la historia de este deporte como pueden ser Ferrari o McLaren. Más adelante continué por interesarme en la evolución de los monoplazas como resultado de los avances tecnológicos y viendo como cada vez se volvían más rápidos, precisos y efectivos.

Es por todo esto que decidí realizar mi Trabajo de Fin de Máster sobre este increíble deporte que es la Fórmula 1. Además, en él es extremadamente importante el uso de modelos predictivos, tanto para predecir el ritmo del coche y el de sus rivales, como para controlar el desgaste de los neumáticos o la potencial pérdida de tiempo en boxes durante una carrera.

\section{Comienzo del proyecto}

Una vez escogido el tema, tocaba planificar el desarrollo del proyecto. Para ello decidí llevar acabo una planificación por sprints. Comenzando por la compresión del problema y la recolección de datos, siguiendo por la creación, entrenamiento y ajuste de los modelos, y acabando por el desarrollo de una aplicación para la interacción con los mismos.

Para llevar a cabo este proyecto decidí escoger GitHub como herramienta de control de versiones, ya que es uno de los requisitos de este proyecto, además de estar ampliamente familiarizado con su tecnología, y Zenhub cómo herramienta de desarrollo ágil, la cual ya he usado con anterioridad. Es aquí dónde encontré mi primer problema en este propósito. Zenhub dispone de un programa de estudiantes que permite utilizar su herramienta de forma gratuita, y así empecé planificando el primer sprint y las primeras tareas. Fue en la preparación del segundo sprint dónde tuve el problema, ese programa gratuito se saturó, por lo que lo inhabilitaron, quedando mi cuenta fuera del mismo. Todo esto hizo que se me complicara la gestión de tareas del proyecto.

\section{Recolección de datos}

Para la recolección de datos inicialmente pasé por contactar con varias páginas web que albergan gran cantidad de información sobre la Fórmula 1. Contacté con 4 de las páginas más relevantes de este deporte: \href{https://www.statsf1.com/}{\textit{statsf1}}, \href{https://www.racing-reference.info/}{\textit{racing-reference}}, \href{https://www.f1-fansite.com/}{\textit{f1-fansite}}, y \href{https://www.motorsportstats.com/}{\textit{motorsportstats}}. Incluso contacté con la página oficial de la \href{https://www.formula1.com/}{\textit{Fórmula 1}}. Algunas de las páginas no me contestaron y otras simplemente me respondieron que no sería posible cederme datos, que no es la política de empresa. 

Tras ver que no fue posible obtener los datos de alguna empresa, tomé la inevitable decisión de recopilarlos yo mismo. Para ello existe de una API llamada \href{https://ergast.com/mrd/}{\textit{Ergast Developer API}}. 

El término \textit{API} (Application Programming Interface o Interfaz de programación de aplicaciones) se refiere a un conjunto de pautas y protocolos que nos permiten la comunicación entre varios componentes de software. Es una interfaz que especifica cómo podemos hacer uso e interactuar con las funcionalidades de un sistema, biblioteca, framework o servicio. 

En el caso de Ergast Developer API es un servicio web experimental que proporciona un registro histórico de datos de carreras de coches para fines no comerciales\cite{eargast:API}. Este servicio nos proporciona datos del deporte de la Fórmula 1, desde el inicio del campeonato en 1950 hasta el día de hoy.

Después de conocer la fuente inicié la recopilación de datos, realizado en varias fases:
\begin{enumerate}
    \item Inicialmente se obtuvieron los datos de todos los pilotos, constructores o equipos y circuitos de la Fórmula 1. Para obtener datos de los circuitos quise obtener la altitud en cuanto a la posición geográfica, ya que afecta notablemente al rendimiento del motor. Para ello me creé una cuenta en la herramienta para desarrolladores de Google, la Google Cloud Platform (GCP). La GCP es una plataforma de servicios de computación en la nube de Google. Se creó para ayudar a las empresas y desarrolladores a crear, implementar y administrar sus aplicaciones y servicios en la nube. Además, nos ofrece una amplia gama de servicios y herramientas. Más concretamente nos proporciona una API llamada \textit{Maps Elevation API}, la cual nos permite a partir de un punto de latitud y longitud, la elevación del terreno entre otros datos. A partir de la información que nos da Ergast (latitud y longitud) he obtenido la altitud geográfica de los circuitos.
 
    \item Más adelante se obtuvieron todos los datos de los resultados de las carreras y las clasificaciones. En este momento nos surge otro problema, sólo obtenemos datos desde el año 2003 de las clasificaciones. Decidí sacar los datos de la página oficial de la Fórmula 1 con técnicas de \textit{webscrapping}. A continuación tuve que crear varios diccionarios para poder asociar a qué circuito y piloto corresponden dichos datos, ya que no cuentan el mismo nombre exacto en la página de la Formúla 1 que en la API de Ergast. Pero al recopilar y hacer el cruce de todos los datos me encontré con que no están todos. Faltan la mayor parte de los datos de clasificación y sólo disponemos de parte de los datos de posición de salida. Por ello usaremos únicamente la información obtenida en la API de Ergast, la cual dispone de los datos de posición de salida para todas las carreras.

    \item En tercer y último lugar lugar quise añadir el dato del tiempo meteorológico de las carreras, que es un factor muy influyente en las carreras. Cuando una carrera es bajo lluvia la influencia del rendimiento del coche baja considerablemente y el desempeño del piloto es de mayor importancia. Es por ello que es un factor muy relevante en las carreras y por lo tanto debe tenerse en cuenta.
    Estos datos no se encuentran en ninguna de las webs de las carreras mencionadas anteriormente y en la API de Ergast tampoco. En un primer lugar consideré a través de la posición geográfica de los circuitos y de la fecha de realización de las carreras, consultar en alguna API de empresas o servicios de meteorología. Tras hacer varias pruebas con la API archive-api.open-meteo.com y la API de wunderground (api.weather.com), no se pudo determinar el tiempo exacto durante la carrera ya que podría haber llovido ese día pero no durante la realización del gran premio. 
    Después de unos días reflexionando sobre cómo abordar este problema, encontré que en wikipedia se muestra cierta información sobre la temperatura del asfalto y sobre si llovió o no. Es por esto que mediante técnicas de \textit{webscrapping} y la librería \textit{BeautifulSoup}, creando un diccionario que detecta si hay palabras que indiquen que ha llovido, se ha establecido si llovió (representado con el valor \textit{wet}) o no (\textit{dry}) durante el gran premio.
\end{enumerate}

\section{Preparación y limpieza de datos}

Tras la recopilación de los datos se procedió a prepararlos y limpiarlos para el modelo. 

\subsection{Fase 1, estados}

En este momento decidí comenzar con el estado de finalización de las carreras. En la API de Ergast además de la posición de finalización de una carrera tenemos el estado en que se terminó esta, a continuación mostramos los estados más comunes en orden descendentes en la siguiente tabla \ref{tabla:estadosfinalcarrerasf1}.

\tablaSmall{Estados de finalización de un piloto en una carrera.}{l c}{estadosfinalcarrerasf1}
{ \multicolumn{1}{l}{Estados} & Representación del estado \\}{ 
Finished & Terminó la carrera sin problemas \\
+1 Lap & Terminó la carrera con una vuelta de retraso \\
Engine & Problemas en el motor del vehículo \\
Accident & Estuvo involucrado en un accidente \\
Collision & Estuvo involucrado en una colisión \\
Spun off & Se salió de pista durante la carrera \\
Gearbox & Problemas en la caja de cambios \\
Did not qualify & No logró calificar para la carrera \\
Suspension & Problemas en la suspensión del vehículo \\
Electrical & Problemas eléctricos en el vehículo \\
Transmission & Problemas en la transmisión del vehículo \\
Brakes & Problemas en los frenos del vehículo \\
Clutch & Problemas en el embrague del vehículo \\
}

Había demasiados estados finales, por lo que los reduje a tres estados para simplificarlo. Podemos verlos en la tabla \ref{tabla:estadossimplesfinalcarrerasf1}. 

\tablaSmall{Estados de finalización simplificados.}{l c}{estadossimplesfinalcarrerasf1}
{ \multicolumn{1}{l}{Estados} & Representación del estado \\}{ 
Finished & Terminó la carrera sin problemas \\
Driver mistake & No terminó por un error de pilotaje \\
Mechanical failure & No terminó por problemas mecánicos del vehículo \\
Engine failure & No terminó por problemas en el motor del vehículo \\
}

\subsection{Datos del piloto, circuitos y constructores}
Más adelante crucé el \textit{dataset} con los datos del piloto, de los circuitos y de los equipos, los cuales había obtenido con anterioridad. Aquí se contemplan datos como por ejemplo la nacionalidad del piloto, el país donde se ubica el circuito o la nacionalidad del equipo. 
A la hora de obtener la nacionalidad y el país del equipo o circuito, observé que para el modelo sería interesante que ese dato fuera igual en los tres casos. Es por ello que modifiqué la nacionalidad de los pilotos para que aparezca en forma país y no de nacionalidad. 
Por otra parte, como amante del deporte que soy, tuve en cuenta que por temas de patrocinios muchos equipos cambian constantemente de nombre durante su historia, y es muy imperante que se tenga esto en cuenta para que los datos de un mismo equipo no se traten de forma separada. Con el fin de unificar los nombres del mismo equipo, busqué información sobre la historia de todos los constructores, la cual podemos ver la siguiente imagen \ref{fig:constructor_history_min}, para modificar este dato.

\imagen{constructor_history_min}{Extracto de los cambios de nombre en la historia de algunas de las escuderías\cite{reddit:f1teamhistory}.}{1}

Además, utilicé la fecha de realización del gran premio y la fecha de nacimiento del piloto para calcular la edad del piloto durante la carrera. Esto es importante, ya que con el tiempo los pilotos están más experimentados, por lo cual son más rápidos y cometen menos errores como podemos ver en la figura \ref{fig:errorespilotoedad}.

\imagen{errorespilotoedad}{Promedio de errores de los pilotos según la edad}{.8}

Por último se obtuvieron las puntuaciones de cada año del campeando tanto en constructores como en pilotos. Estos datos se pueden obtener directamente de la API de Eargast. Pero cómo la puntuación en función del resultado en carrera ha sido modificado con el tiempo, se va a proceder a adjudicar los puntos en función de la posición final de cada carrera con el sistema de puntuación actual. En este sistema sólo puntúan los 10 primeros pilotos, tal como podemos ver en la tabla \ref{tabla:puntuacioncarrerasf1}.
    \tablaSmall{Puntuación de cada piloto en función de la posición final de carrera.}{l c}{puntuacioncarrerasf1}
    { \multicolumn{1}{l}{Posición} & Puntuación \\}{ 
        1° & 25\\
        2° & 18\\
        3° & 15\\
        4° & 12\\
        5° & 10\\
        6° & 8\\
        7° & 6\\
        8° & 4\\
        9° & 2\\
        10° & 1\\
    }

\subsection{Fase 3, Ganadores, \textit{polemans}, fiabilidad de coches y consistencia de pilotos}
Con los datos de las posiciones de salida obtendremos los \textit{polemans}. La \textit{pole} es para el piloto que consigue hacer la vuelta más rápida en clasificación y por ello sale en primer lugar en la carrera. El \textit{poleman} es el piloto que consigue la \textit{pole}. Es interesante conocer este dato porque en muchos circuitos en los cuales es muy difícil adelantar y salir por delante es de gran importancia como vemos en el gráfico de la figura \ref{fig:winnerpole}, el 40\% de las victorias es saliendo desde la primera posición.

\imagen{winnerpole}{Porcentaje de victorias cuando el piloto sale en la primera posición.}{.6}

Y si comparamos las victorias saliendo desde la tercera posición o mejor el dato es aún más relevante (figura \ref{fig:winneron3grid}), un 80\%.

\imagen{winneron3grid}{Porcentaje de victorias cuando el piloto sale en las tres primeras posiciones.}{.8}

Además, vamos a obtener el ganador del gran premio a través de las posiciones de salida, para más adelante poder predecir este dato.

De igual modo es importante conocer la fiabilidad de los coches y la consistencia de los pilotos. En este caso usaremos la información de finalización de carrera (tabla \ref{tabla:estadossimplesfinalcarrerasf1}), en función del total de carreras. Para la consistencia del piloto se usará el estado \textit{driver mistake} y para la fiabilidad de los coches los estados \textit{mechanical failure} y \textit{engine failure}.

\subsection{Limpieza de datos}

Más adelante se procedió con la limpieza de datos, ya que debemos comprobar si hay algún dato que sea nulo, ya que los valores nulos afectarán negativamente a la eficiencia de los modelos \cite{art:impactmissdata}. 
Al comprobar los datos inexistentes, se eliminará la siguiente información: 

\begin{itemize}
	\item Tiempos de carrera: no contamos ni con el 50\% de los tiempos.
	\item Vuelta rápida de piloto en carrera: al igual que con los tiempos de carrera falta más de la mitad de los datos, y por ello la velocidad media de esa vuelta también será eliminada.
    \item Código de piloto y número de piloto: estos números no aportan información y además no hay prácticamente registros de ello.
\end{itemize} 

Datos descargados que se eliminaran porque no aportan ninguna información sobre las carreras: 
    \begin{itemize}
        \item Urls tanto de pilotos como de circuitos, carreras, o constructores.
        \item Nombres y/o apellidos de pilotos y constructores, ya que contamos con el id o alias de cada uno de ellos.
        \item Nacionalidad de piloto o equipo, y nombre de la localidad del circuito. Como ya hemos convertido la nacionalidad a nombre del país, ya no es necesario conocer dicha información.
    \end{itemize}


\section{Selección de características y codificación de los datos}

En este punto se deben escoger las características que son más importantes para el entrenamiento del modelo. Para lograr esto, contrastaremos el uso de un algoritmo de selección de características frente a la selección manual de los rasgos que, en mi opinión, son más cruciales según mis muchos años de experiencia siguiendo este deporte. 

\subsection{Codificación de los datos}

Es necesario tener los datos codificados para realizar la selección automática de características, ya que los modelos trabajan con datos numéricos.

En el aprendizaje automático existen dos grandes codificadores de características en función del tipo de variable. 
\begin{enumerate} 
    \item Para variables categóricas con diferentes categorías se suele utilizar la codificación \textit{One-Hot}, en la cual se crea una columna binaria para cada categoría.
    \item En variables con un orden jerárquico se usan codificaciones ordinales, las cuales asignan a cada valor diferente de la variable un valor numérico normalmente ascendente o descendente.
\end{enumerate}

Para nuestros datos se han escogido las siguientes codificaciones para cada uno de las variables:

\begin{itemize}
    \item Año, posición final en carrera, posición de salida, ronda o serie, vueltas terminadas en carrera, puntos obtenidos tras la carrera, latitud o longitud de la posición geográfica del circuito, altitud del circuito respecto del nivel del mar, edad del piloto, consistencia del piloto y fiabilidad del coche: estos datos ya son numéricos así que no es necesario codificarlos.
    \item Fecha del gran premio: para este dato hemos pasado la fecha a segundos con la referencia de la fecha mas antigua.
    \item Id de circuito, piloto y equipo: para esta variable se ha usado la codificación ordinal para asignar a cada piloto, circuito y equipo un número diferente de cada variable.
    \item Estados de finalización de carrera (estado final y estado simple final): para los estados se ha escogido también una codificación ordinal, asignando un número a cada variable.
    \item Clima: como tenemos dos tipos de climas se ha decidido codificarlos utilizar el método \textit{One-Hot}, por lo que pasamos a tener dos variables en vez de una. Cada variable indica si llovió o no durante la carrera.
    \item Fecha de nacimiento del piloto: para este dato hemos utilizado el mismo criterio que con la fecha del gran premio, hemos pasado ese día a segundos con la referencia de la fecha mas antigua de nacimiento.
    \item País de procedencia de piloto, equipo y circuito: se ha considerado que este dato debía ser codificado con \textit{One-Hot} debido a que el algoritmo debe poder detectar cuando un piloto o equipo corre en el gran premio de su país de procedencia de una mejor forma.
    \item Ganador del gran premio: no se ha codificado ya que ya es un dato numérico que representa un 1 si el piloto queda en primer lugar tras la carrera o un 0 si no.
    \item \textit{Poleman} del gran premio: de igual modo que el ganador del gran premio no se ha necesitado codificar.
\end{itemize}

\subsection{Selección de características manual}

En primer lugar hice la selección manual. Gracias a este enfoque logro tener un mayor control sobre qué características se incluyen o excluyen en el modelo final, lo que me brinda la oportunidad de aplicar mi conocimiento y experiencia en este campo. 
Estas son las características elegidas:

\begin{itemize}
    \item Año: el año es importante ya que tenemos que conocer este dato para distinguir entre carreras de un año y otro.
    \item Id de circuito, piloto y equipo: valores necesarios para diferenciar entre pilotos y equipos en cada circuito.
    \item Posición de salida del piloto: esta variable es de suma importancia en circuitos de complejidad de adelantamiento.
    \item Posición final del piloto en carrera: este dato es una de las variables objetivo del proyecto.
    \item Clima en carrera: uno de los valores más importantes en mi opinión, en mojado los rendimiento de los coches no son demasiado importantes y cobra mayor relevancia la destreza del piloto.
    \item País de procedencia de piloto, equipo y circuito: los pilotos de carreras suelen tener mayor motivación cuando corren en casa, al igual que cuando corren en el país de procedencia del equipo.
    \item Altitud sobre el nivel del mar donde se encuentra el circuito: los motores de los coches de Fórmula 1 se ven afectados por este dato, esto es por la cantidad de oxigeno en el aire. A mayor altitud menor concentración de oxígeno y mayor exigencia para los motores, ya que son motores de combustión y el oxígeno es de vital importancia en la explosión del combustible.
    \item Edad del piloto durante el gran premio: la edad es importante, ya que cuando un piloto es joven es menos experimentado y suele arriesgar más y por tanto comete más errores. Pero también cuando los pilotos son muy mayores suelen perder reflejos y algunos pierden la motivación para correr. Esto lo pudimos ver anteriormente en la figura \ref{fig:errorespilotoedad}.
    \item Ganador de la carrera: variable objetivo del proyecto.
    \item Poleman de la carrera: variable objetivo del proyecto.
    \item Consistencia del piloto: esta variable nos indica la consistencia del piloto a la hora de cometer errores, esto es importante porque cuantos más errores cometen más fácil es que no acaben la carrera.
    \item Fiabilidad del coche: es muy importante conocer este dato, en caso de un coche con poca fiabilidad es posible que el coche sufra un fallo en carrera y abandone. Podemos recordar la época de Fernando Alonso en McLaren con el motor honda entre los años 2015 y 2018 con la fiabilidad de los coches ese año, ilustrado en la figura \ref{fig:fiabilidadcar2015-2018}. En dos de cada 10 carreras fallaban los dos coches abandonando por fiabilidad. Podemos decir sin lugar a dudas que fue el peor coche en cuanto a fiabilidad de esa época.
    \imagen{fiabilidadcar2015-2018}{Fiabilidad de los coches entre 2015 y 2018}{1}
\end{itemize} 

\subsection{Selección de características automática}

Para esta tarea contemplamos dos métodos muy efectivos, la eliminación recursiva o \textit{Recursive Feature Elimination} y la eliminación hacia atrás o \textit{Backward Elimination}.

La técnica de eliminación hacia atrás comienza con todas las características y elimina una a una en cada iteración. Entonces, en cada iteración de esta técnica se entrena y evalúa un modelo con las variables disponibles. La característica menos significativa es la eliminada, tomando como criterio el peso de la misma en esa iteración. Esto se repite hasta llegar al criterio de parada.

Elgoritmo RFE o \textit{Recursive Feature Elimination}, realmente es un tipo de eliminación hacia atrás, pero tiene la ventaja de ser compatible con varios algoritmos de aprendizaje automático, lo que lo convierte en una herramienta flexible y adaptable. Se puede combinar con algoritmos de regresión, clasificación u otras estrategias de modelado, brindándonos la flexibilidad de manejar varios problemas y conjuntos de datos. Además, proporciona una medida de importancia o relevancia para cada característica en función de cómo contribuye al modelo final. Dado que nos permite identificar los rasgos que tienen mayor influencia en la toma de decisiones del modelo, será particularmente útil para nuestro propósito.

Este algoritmo se ha combinado con varios modelos para hacer una selección más óptima. Estos modelos son: \textit{Decision Tree Regressor} y \textit{Linear Regression}. Los dos son modelos de regresión ya que queremos una elección lineal de características. Por un lado los árboles de decisión son modelos muy versátiles que nos van a permitir capturar las relaciones no lineales y podremos detectar interacciones entre las diferentes características. Y por otra parte el algoritmo de regresión lineal tiene la ventaja de ser más interpretable y computacionalmente más eficiente.

Tras la ejecución del algoritmo se han eliminado las siguientes características:

Para el modelo con variable objetivo resultado de pilotos en carrera
\begin{enumerate}
    \item Nacionalidades de constructores de Hong Kong, Nueva Zelanda, Sudáfrica, México, Rusia.
    \item Posición geográfica en latitud y longitud.
    \item Fecha de carrera.
\end{enumerate}

Modelo con variable objetivo poleman de la clasificación
 \begin{enumerate}
    \item Nacionalidades de pilotos de Venezuela y Zimbabwe.
    \item Posición geográfica en latitud y longitud.
    \item Fecha del gran premio.
    \item Ronda o serie.
    \item Año.
    \item Fecha nacimiento.
\end{enumerate}

Para el modelo con variable objetivo ganador de la carrera.
 \begin{enumerate}
    \item Edad del piloto.
    \item Posición geográfica en latitud y longitud.
    \item Fecha del gran premio.
    \item Ronda o serie.
    \item Año.
    \item Fecha nacimiento.
\end{enumerate}


\section{Entrenamiento}
Para llevar a cabo el entrenamiento se ha escogido la librería \href{https://scikit-learn.org/stable/}{\textit{scikit-learn}}, la cual cuenta con una gran cantidad de algoritmos y modelos de aprendizaje automático.

Se ha decidido hacer una división del 80\% para entrenamiento de datos y un 20\% para evaluación, para darle al modelo muchos ejemplos permitiendo descubrir y comprender patrones subyacentes en los datos. Como resultado, el modelo puede volverse más preciso y general. Además, reservar ese 20\% final de los datos para la evaluación le permite evaluar el rendimiento en datos a los que no estuvo expuesto durante el entrenamiento. Esto le da una indicación concreta de qué tan bien puede extrapolar a partir de nuevos datos y hacer predicciones. 
Inicialmente se pensó en la función \texttt{train\_test\_split} de \textit{scikit-learn} para llevar a cabo esta división. La cual nos permite dividir matrices o listas en subconjuntos aleatorios de entrenamiento y prueba \cite{sklearn:traintestsplit}.

Finalmente se utilizará la validación cruzada para encontrar la mejor división de datos posible, manteniendo el 20\% de datos de prueba. La validación cruzada o cross-validation es una técnica que consiste en dividir el conjunto de datos en subconjuntos de entrenamiento y prueba, y evaluar cada subconjunto para encontrar el más óptimo. Para ello se utiliza la librería \textit{scikit-learn} y su algoirtmo KFold, el cual realiza divisiones del conjunto de datos en K partes iguales, utilizando K - 1 partes para el entrenamiento y la parte restante para validación en cada  una de las iteraciones. Asignando a K el valor de 5 para obtener ese porcentaje del 80\% de entrenamiento frente al 20\% de prueba. Con esto se logra maximizar la utilización de datos, gracias a permitir el uso de todo el conjunto tanto para entrenamiento como para validación.

\subsection{Modelos del entrenamiento}
Para el cálculo de las posiciones de carrera, se van a utilizar los siguientes modelos de regresión: Linear Regression, Decision Tree Regressor, Random Forest Regressor y Support Vector Regression (SVR).

\begin{itemize}
    \item Linear Regression: este modelo tiene como objetivo crear una relación lineal entre la variable objetivo y las demás variables. Se aplica a problemas de regresión donde el objetivo es predecir valores numéricos. Además este modelo es sumamente eficiente en cuanto computación.
    \item Decision Tree Regressor: es un modelo que se basa en árboles de decisión. Crea una estructura de árbol tratando de que las ramas representen posibles respuestas a las preguntas que forman los nodos con respecto a las características. Cada hoja del árbol recibe un valor de salida tras la división recursiva en subconjuntos del conjunto inicial de datos. Se aplica en problemas que requieran identificar relaciones no lineales.
    \item Random Forest Regressor: el propósito del modelo es hacer predicciones a través de la combinación de varios árboles de decisión. El resultado final se obtienen promediando las predicciones de cada uno de los arboles, los cuales se han entrenado con una muestra aleatoria diferente a las demás. Además, cuenta con la ventaja de reducir el sobreajuste y aumentar la eficiencia. Es aplicado a problemas con características de alta dimensión y puede gestionar un gran volumen de datos.
    \item Support Vector Regression: modelo que predice utilizando vectores de soporte. Los puntos de los vectores de soporte se encuentran en el borde del límite de decisión o en la zona que afectará en mayor medida cómo se define la función de regresión. El modelo controla una tolerancia de error, buscando una función de regresión que se ajuste mejor a los datos y reduzca la discrepancia entre la predicción y el valor real. Cuando nuestros datos contienen características no lineales o incluso con valores atípicos, este modelo es sumamente útil en problemas de regresión.
\end{itemize}

Y para el cálculo del \textit{poleman} y ganador, problemas de clasificación, se usará: Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Classification (SVC), KNeighbors Classifier, Gaussian NB.

\begin{itemize}
    \item Logistic Regression: es utilizado para resolver problemas donde las variables objetivo son binarias o representan categorías. Se usa una función logística para calcular la probabilidad con la que una instancia dada pertenezca a una clase en particular. Se sustenta en la relación lineal encontrada entre características y variable objetivo. Además, convierte el resultado en una probabilidad gracias a una función de activación. Utilizado sobre todo para problemas de clasificación binaria, pero se puede expandir a problemas con variables objetivo categóricas.
    \item Decision Tree Classifier: funciona igual que el Decision Tree Regressor pero con la particularidad de que en este cada hoja del árbol recibe una etiqueta de clase tras la división recursiva del conjunto de datos y no un valor.
    \item Random Forest Classifier: al igual que en la regresión, realiza las predicciones a través de la combinación de varios árboles de decisión. El resultado se obtiene promediando la clasificación total de los árboles.
    \item Support Vector Classification: los vectores utilizados en este modelo se usan para dividir instancias en clases. La diferencia con el SVR es que ahora buscamos el mejor hiper plano en el cual haya la mayor distancia de mayor entre clases. Permite el uso de datos tanto linealmente separables como no separables gracias a funciones kernel. Gran elección en problemas de clasificación de variables categóricas o binarias.
    \item KNeighbors Classifier: usa el algoritmo K-Nearest Neighbors. Asigna etiquetas de los k vecinos cercanos a las instancias. Se vale de la noción de que las instancias parecidas pertenecen a la misma clase con frecuencia. Es muy eficiente y sencillo para problemas de clasificación siempre y cuando la elección del número de k vecinos no sea demasiado alta.
    \item Gaussian NB (Naive Bayes): este modelo se basa en el teorema de Bayes, además de asumir que los datos forman una distribución gaussiana. Utiliza la regla de Bayes para determinar la probabilidad de pertenecer a una clase en particular. Se asume la independencia entre características, algo ingenuo, de ahí su nombre. Para problemas de clasificación con variables continuas y distribuidas en forma normal es muy eficiente.
\end{itemize}

\subsection{Comparación de las soluciones y evaluación de los diferentes modelos utilizados}

Vamos a comparar los algoritmo en función de la variable a predecir y el tipo de selección utilizado. La evaluación se ha llevado a cabo con la métrica R2 score, la cual cuenta con valores en el intervalo (-$\infty$,1], que implican las siguientes opciones:
\begin{itemize}
    \item Número negativo: el modelo es peor que predecir con la media del valor.
    \item 0: el modelo es igual que predecir con la media del valor.
    \item Número positivo en el intervalo (0,1): el modelo es mejor que predecir con la media del valor.
    \item 1: Ajuste perfecto, todas las predicciones coinciden con la realidad.
\end{itemize}

\subsubsection{Variable objetivo: posición final del carrera}
En la figura \ref{fig:model_race_pos} podemos apreciar que tanto el algoritmo RFE  como la selección manual consiguen una similar puntuación. También se observa que tanto el modelo SVR como el Decision Tree Regressor obtienen una puntuación demasiado baja, esto se puede deber a que el conjunto datos no tiene muchas relaciones lineales. Sin embargo, el modelo Random Forest Regressor nos da valores más aceptables. Esto se puede deber a que uno de sus puntos fuertes es trabajar con problemas que tienen un conjunto de datos muy grande y de alta dimensión, como es nuestro caso.

\imagen{model_race_pos}{Eficiencia de los modelos para predecir la posición final del carrera.}{.8}

Sin embargo, en la imagen \ref{fig:model_race_pos_t} podemos apreciar que el conjunto de datos elegido mendicante el uso del algoritmo RFE reduce en hasta un 50\% de media los tiempos de ejecución. Además, podemos concluir que a pesar de que el modelo SVR tarde casi 80 veces más en entrenarse que el Random Forest Regressor no alcanza ni un cuarto de su eficiencia.

\imagen{model_race_pos_t}{Tiempos de ejecución de los algoritmos para predecir la posición final del carrera.}{.8}

\subsubsection{Variable objetivo: ganador de la carrera}
En este caso la variable a predecir es binaria. La eficiencia de los algoritmos para este problema es sustancialmente mayor que en el caso anterior. Hemos conseguido una eficiencia cercana al 100\%, algo muy útil para predecir en las carreras. El único modelo que no logra tal eficiencia es el modelo de Gaussian Naive Bayes, el cual no logra ni alcanzar el 40\% de los aciertos. Pero en este caso no se nota demasiado el uso de una selección u otra.
\imagen{model_race_winner}{Eficiencia de los modelos para predecir el ganador de la carrera.}{.8}

Los tiempos de ejecución (figura \ref{fig:model_race_winner_t}) marcan el mismo patrón que en el caso anterior, el algoritmo RFE es un 50\% más rápido (exceptuando el modelo de árboles de decisión y el de regresión logística), lo que supone una gran ventaja de computación. Además, podemos ver que estos algoritmos son muy rápidos, apenas tardan unos segundos en ejecutarse.

\imagen{model_race_winner_t}{Tiempos de ejecución de los algoritmos para predecir el ganador de la carrera.}{.8}

\subsubsection{Variable objetivo: ganador de la \textit{pole}}
Como en el caso anterior hemos conseguido un muy alto porcentaje de acierto gracias a los algoritmos de clasificación, excepto con el modelo de Gaussian Naive Bayes.
\imagen{model_pole_winner}{Eficiencia de los modelos para predecir el ganador de la \textit{pole}.}{.8}

También es importante ver cómo los tiempos de ejecución son muy bajos y se observa el patrón de mejores tiempos para el entrenamiento con selección utilizando el RFE (de igual modo a excepción del modelo de árboles de decisión y del de regresión logística).
\imagen{model_pole_winner_t}{Tiempos de ejecución de los algoritmos para predecir el ganador de la \textit{pole}.}{.8}


\section{Optimización del modelo}
Tal como hemos observado en la imagen \ref{fig:model_race_pos} el algoritmo Random Forest Regressor ha conseguido la mayor de las puntuaciones, y el Decision Tree Regressor la peor puntuación, y por ello vamos a escoger estos dos modelos con el conjunto de datos seleccionado por el algoritmo RFE para el ajuste (ya que es más eficiente computacialmente hablando). No se han escogido los problemas de clasificación porque ya eran bastante precisos y veremos una mayor mejora en las demás opciones. 

\subsection{Random Forest Regressor}
Para la optimización de este modelo se ha creado un diccionario que contiene los parámetros más importantes para el ajuste del modelo y se han generado todas las combinaciones posibles para obtener el conjunto de hiper parámetros que mayor eficiencia sea capaz de conseguir. En este caso el modelo con los parámetros iniciales suele ser bastante bueno, veamos si es posible ajustarlo más para mejorar la solución.

Los hiperparámetros que se van a combinar en sus diferentes posibilidades son \cite{sklearn:randomforestregressor}:
\begin{itemize}
    \item \texttt{\textit{bootstrap}}: indica si se usan muestras bootstrap para construir los árboles. Si no se usa todo el conjunto. Si le indicamos que sí, que es como lo vamos a hacer, tenemos otros parámetros a elegir:
        \begin{itemize}
            \item \texttt{\textit{max\_samples}}: elige el número de muestras a extraer de X para entrenar cada estimador base. Generando con la función \textit{linspace} de la librería \textit{numpy}, la cual nos permite generar x números entre un número inicial y un final, una lista como la siguiente: \textit{[500, 1000, 1500, 2000]}.
            \item \texttt{\textit{oob\_score}}: nos permite indicar si utilizaremos muestras fuera de la bolsa para estimar la puntuación de generalización. Se pondrá en \textit{true}.
            \item \texttt{\textit{random\_state}}: sirve para controlar la aleatoriedad de las muestras bootstrap utilizadas al construir los árboles, además del muestreo de las características a considerar al buscar la mejor división en cada nodo (si el número máximo de características escogido es menor que el número de características totales). Utilizaremos los siguientes valores: 5, 10 y 15.
        \end{itemize}
    \item \texttt{\textit{max\_depth}}: profundidad máxima del árbol. Usaremos los valores:  5, 16, 27, 38, 50.
    \item \texttt{\textit{n\_estimators}}: número de árboles. Se ha generado esta lista de valores a probar: 500, 1000, 1500 y 2000.
    \item \texttt{\textit{criterion}}: función utilizada para determinar la calidad de cada división. Tenemos 4 opciones:
        \begin{itemize}
            \item \texttt{squared\_error} utiliza el error cuadrático medio para minimizar la pérdida de L2 mediante el uso de la media de cada nodo terminal.
            \item \texttt{friedman\_mse} usa el error cuadrático medio con la puntuación de mejora de \textit{Friedman} para escoger las posibles divisiones.
            \item \texttt{absolute\_error} mediante el error absoluto medio  minimiza la pérdida L1 gracial al uso de la mediana de cada nodo terminal. El problema es que esta función es significativamente más lenta que \texttt{"squared\_error"}, y por ello es la única que no se probará.
            \item \texttt{poisson} divide los datos gracias a la reducción de la desviación de Poisson. 
        \end{itemize}
    \item \texttt{\textit{max\_features}}: número máximo de características s considerar en la búsque de la mejor división. Crearemos una lista con 10 números del tipo \textit{float}, desde 0.1 hasta 1. Si le pasamos un número decimal entre 0 y 1 multiplicará este por el número total de características que tenemos, 109, obteniendo así el número que se utilizará en el parámetro. Hemos generado con \textit{linspace} la siguiente lista: \textit{[0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7000000000000001, 0.8, 0.9, 1.0]}. Además podemos indicarle dos funciones para este parámetro: \textit{sqrt} para que el valor del parámetro sea la raíz cuadrada del total de carcterísticas y \textit{log2} para el logartimo en base dos.
    \item \texttt{\textit{warm\_start}}: indica si se reutilizan o no las soluciones de anteriores para añadir y ajustar más estimadores al conjunto. Si es falso, se usa un bosque completamente nuevo. Probaremos indicando que se use y que no se use por separado.
    \item \texttt{\textit{ccp\_alpha}}: este parámetro define la complejidad de costes mínima para la poda, es decir, se elige el subárbol que cuente con la mayor complejidad de costes que sea menor que el valor indicado. Se comprobarán valores entre 0 y 0.1.
    \item\texttt{\textit{min\_samples\_split}}: número mínimo de muestras para hacer la división de los nodos internos. Probando con 2, 5 y 10.
    \item \texttt{\textit{min\_samples\_leaf}}: número mínimo de muestras para estar en un nodo hoja. Se probarán los siguientes valores: 1, 2 y 4.
    \item \texttt{\textit{verbose}}: este valor controlará la verbosidad al ajustar y predecir los datos. Utilizaremos los siguientes valores: 0, 2 y 5.
    \item \texttt{\textit{n\_jobs}}: número de trabajos en paralelo durante el entrenamiento. Se establecerá en -1 para que se escoja el número máximo de procesadores disponibles.
\end{itemize}
Para hacer las pruebas con todas las combinaciones se usará la librería \textit{itertools} con su función \textit{product},la cual nos permite a partir de varias listas de valores generar una lista con todas las combinaciones posibles, que son 2808.
Tras 5 horas de ejecución y la gran cantidad de parámetros y combinaciones utilizadas, no se ha conseguido mejorar la puntuación de los valores por defecto, ya que este algoritmo es bastante bueno en esa configuración.

\subsection{Decision Tree Regressor}
En este caso es más probable que consigamos una mejora, pero ¿seremos capaces de generar una solución mejor que para el caso anterior?
Para ello los hiperparámetros que se van a combinar en sus diferentes posibilidades son \cite{sklearn:decisiontreeregressor}:
\begin{itemize}
    \item \texttt{\textit{max\_depth}}: profundidad máxima del árbol. Vamos a utilizar la función \textit{linspace} de la librería \textit{numpy}. Le hemos dado 5 y 50 como rango y obtenemos las siguientes: 5, 16, 27, 38, 50.
    \item \texttt{\textit{criterion}}: función utilizada para determinar la calidad de cada división. Tenemos 4 opciones:
        \begin{itemize}
            \item \texttt{squared\_error} utiliza el error cuadrático medio para minimizar la pérdida de L2 mediante el uso de la media de cada nodo terminal.
            \item \texttt{friedman\_mse} usa el error cuadrático medio con la puntuación de mejora de \textit{Friedman} para escoger las posibles divisiones.
            \item \texttt{absolute\_error} mediante el error absoluto medio  minimiza la pérdida L1 gracias al uso de la mediana de cada nodo terminal. El problema es que esta función es significativamente más lenta que \texttt{"squared\_error"}, por ello va a ser la única en no utilizarse.
            \item \texttt{poisson} divide los datos gracias a la reducción de la desviación de Poisson. 
        \end{itemize}
    \item \texttt{\textit{max\_features}}: número máximo de características a considerar en la búsqueda de la mejor división. Usaremos la misma lista escogida en el caso anterior.
    Además podemos indicarle dos funciones para este parámetro: \textit{sqrt} para que el númeor máximo de carcterísticas sea la raíz cuadrada del total y \textit{log2} para usar el logaritmo en base dos.
    \item \texttt{\textit{splitter}}: estrategia que se usa para la división de los nodos del árbol. Tenemos dos opciones disponibles:
        \begin{itemize}
            \item \texttt{best}: escoge la mejor división.
            \item \texttt{random}: elige una división aleatoria.
        \end{itemize}
    \item \texttt{\textit{ccp\_alpha}}: este parámetro define la complejidad de costes mínima para la poda, es decir, se elige el subárbol que cuente con la mayor complejidad de costes que sea menor que el valor indicado. Se utilizará el valor por defecto \textit{0.0} ya que queremos la mayor complejidad.
    \item\texttt{\textit{min\_samples\_split}}: número mínimo de muestras para hacer la división de los nodos internos. Los valores probados son: 2, 5 y 10.
    \item \texttt{\textit{min\_samples\_leaf}}: número mínimo de muestras para estar en un nodo hoja. Se probarán los siguientes valores: 1, 2 y 4.
\end{itemize}
Se han conseguido probar 3510 combinaciones de parámetros generadas como en el caso anterior con la función \textit{product} de la librería \textit{itertools}. Este modelo es sustancialmente más rápido y hemos logrado ejecutar todas las posibilidades en cuestión de 15 minutos.

\subsection{Comparación de valores}
En la figura \ref{fig:hiperparams} podemos apreciar los valores conseguidos sin ajuste, con ajuste y con el conjunto de datos escogido a mano.

Se observa que en el modelo Decision Tree Regressor se ha conseguido gracias a ajustar los hiperparámetros obtener un acierto del 45\% respecto del modelo por defecto. Sin embargo con el modelo Random Forest Regressor hemos logrado únicamente 5.5\% más de rendimiento. El ajuste de hiperparámetros por defecto en este modelo es una solución bastante buena, pero se puede ajustar para ganar algo más de rendimiento. En cuanto al modelo de árboles de decisión hemos tenido que ajustarlo para poder exprimir su máximo rendimiento, algo que queda lejos de la solución con los parámetros por defecto.

\imagen{hiperparams}{Valores anteriores y valores conseguidos con el ajuste de los hiperparámetros.}{.8}

\section{Aplicación para interacción}

Tras haber realizado los entrenamientos y ajustes, llegamos a la parte final del proyecto, el desarrollo de la aplicación que nos va a permitir hacer predicciones. Comenzaremos con la arquitectura, más adelante se diseñará la interfaz de usuario y por último la lógica e implementación del modelo.

\subsection{Arquitectura de la aplicación}

En esta fase tenía que diseñar la interfaz de usuario para la aplicación y toda la lógica que conlleva, pero antes debía escoger el entorno en el que desarrollarla.

\subsection{Entorno de desarrollo}
En este momento tuve que decidir que entorno escoger para el desarrollo de la aplicación. Contaba con diferentes opciones:
\begin{enumerate}
    \item Desarrollar una aplicación WinForms de .NET que es la tecnología con la que actualmente trabajo y estoy muy familiarizado con ella. Acabé descartando esta opción porque al ser una aplicación no demasiado compleja, esta tecnología requiere mayor esfuerzo. Además sólo se podría lanzar en Windows y no quería limitar al usuario final. 
    \item Hacer una aplicación para Android y que pudiera ejecutarse en cualquier móvil. También descarte esta opción porque de nuevo requería mayor esfuerzo de la complejidad de la propia app. Aunque pudiera ejecutarse sólo en un móvil Android, hoy en día la mayor parte de la gente cuenta con uno.
    \item Python: al haber utilizado este mismo entorno y lenguaje para hacer el modelo, eliminaría la complejidad de unir dos sistemas diferentes. Escogí esta opción ya que además de minimizar esfuerzos me permitía desarrollar una aplicación de una forma más simple y para cualquier dispositivo que ejecutara python, el mismo lenguaje con el que he construido el modelo. 
\end{enumerate}

\subsection{Diseño de la interfaz de usuario de la aplicación}
Para hacer un primer boceto quise contar ya con la librería que usaría para poder desarrollar la interfaz, y python cuenta con muchas librerías con las que se pueden desarrollar aplicaciones y de todas ellas las más conocidas son:
\begin{itemize}
    \item Tkinter: interfaz Tk, interfaz por defecto de Python para el kit de herramientas de GUI Tk \cite{python:tkinter}.
    
    \item PyQt: es un conjunto de enlaces de Python para el framework Qt \cite{riverbankcomputing:pyqt}. Nos proporciona una gran cantidad de widgets, y es  muy conocida por su capacidad para crear interfaces muy personalizables y atractivas para el usuario.

    \item PySide: es otro conjunto de enlaces de python para Qt.
    
    \item Kivy: es un framework de python de código abierto para desarrollar aplicaciones multiplataforma. Está más enfocado a dispositivos de uso táctil, por lo que queda descartada.
    
    \item wxPython: conjunto de herramientas GUI (interfaz gráfica) multiplataforma y de código abierto. Su punto fuerte es su facilidad de uso y capacidad para crear interfaces gráficas robustas y altamente funcionales \cite{wxpython:wxpython}.
\end{itemize}

Inicialmente escogí \textit{Tkinter} por su simpleza, su curva de aprendizaje es muy corta. Con esta librería realicé el primer boceto, con unos pocos desplegables en formato vertical para seleccionar el piloto y demás datos, el cual podemos ver en la imagen \ref{fig:boceto_app_ini}:

\imagen{boceto_app_ini}{Primer boceto de la interfaz de usaurio.}{.4}

La disposición vertical de los desplegables no me convencía así que decidí ponerlos en horizontal y añadir una imagen de fondo (\ref{fig:boceto3_app}).

\imagen{boceto3_app}{Boceto de la interfaz de usuario con desplegables horizontales y con imagen de fondo.}{.7}

Cuando intenté poner alguna etiqueta para poner los datos del desplegable y algún botón me di cuenta de que con la librería \textit{Tkinter} tenía lagunas limitaciones, por lo que decidí probar con la librería \textit{wxPython}. Con esta otra librería en poco tiempo conseguí poner los desplegables con etiquetas de texto y un cuadro de texto a modo de log para ver que pasos seguía la aplicación mientras trataba los datos antes de la predicción (figura \ref{fig:boceto0_app2}).

\imagen{boceto0_app2}{Boceto de la interfaz de usuario realizado con la librería \textit{wxPython}.}{.7}

Tras añadirle los botones para predecir los resultado, como vemos en la figura \ref{fig:final_app2}, seguía sin convencerme el diseño que podíamos alcanzar con esta librería.

\imagen{final_app2}{Diseño de la interfaz de usuario de la aplicación con WX.}{.7}

\subsection{Funcionalidad de la aplicación}

Para poder interactuar con el modelo se guardaron los modelos con la librería \textit{joblib} en el entrenamiento y cargaron en la app. \textit{Joblib} nos provee de varias funciones, entre ellas \texttt{load} y  \texttt{dumb}. Estas funciones nos permiten guardar y cargar objetos de python en archivos binarios, o lo que es lo mismo una manera muy efectiva de serializar y deserializar objetos de python, algo muy útil para procesamiento de datos y aprendizaje automático \cite{python:joblib}.

Para poder ejecutar las predicciones se obtendrán los datos de la propia API de Ergast y más adelante se codificarán con los mismos codificadores que se han utilizado en la codificación para el entrenamiento, también gracias a las funciones de \textit{joblib} para guardarlos y luego cargarlos en la app. 

Como hemos visto en la arquitectura se han creado 5 archivos para llevar a cabo la lógica:
\begin{itemize}
    \item \texttt{AppCircuits}: para obtener los datos de los circuitos de la temporada escogida.
    \item \texttt{AppConstructors}: para obtener los datos de los equipos de la temporada escogida.
    \item \texttt{AppDrivers}: para obtener los datos de los pilotos de la temporada escogida.
    \item \texttt{AppResults}: para obtener los datos de los resultados de la clasificación de la carrera escogida para poder hacer la predicción de la posición de carrera o si ha ganado o no la carrera.
    \item \texttt{AppCoder}: para combinar y codificar todos los datos obtenidos.
    \item \texttt{DialogSelectGrid}: para la ventana emergente de elección de posiciones de salida.
\end{itemize}
